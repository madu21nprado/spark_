
# ğŸ’¡ Projeto: AnÃ¡lise de Dados com Azure Databricks & Spark

**Autor(a): Maria Eduarda Prado**

## ğŸ“˜ DescriÃ§Ã£o

Este projeto foi desenvolvido como parte dos desafios prÃ¡ticos da DIO, com o objetivo de aplicar os conhecimentos adquiridos sobre o uso do **Azure Databricks** e o **Apache Spark** em anÃ¡lises de dados.

Utilizamos a plataforma de nuvem para criar um ambiente escalÃ¡vel, processar dados com PySpark e extrair insights relevantes a partir de um dataset simulado de vendas.

---

## ğŸ”§ Tecnologias e Ferramentas

- Microsoft Azure
- Azure Databricks
- Apache Spark
- PySpark
- Python
- Git & GitHub

---

## ğŸš€ Etapas Desenvolvidas

### âœ… 1. CriaÃ§Ã£o do Workspace e Cluster no Azure Databricks

O primeiro passo foi a criaÃ§Ã£o de um workspace Databricks e de um cluster com configuraÃ§Ã£o padrÃ£o para executar notebooks PySpark.

*Exemplo de configuraÃ§Ã£o:*
- Runtime: 11.3 LTS (Apache Spark 3.3.0)
- Worker Nodes: Standard_DS3_v2
-

### âœ… 2. Leitura e VisualizaÃ§Ã£o do Dataset

O dataset (`vendas.csv`) foi carregado no Databricks FileStore e lido com o PySpark.

```python
df = spark.read.csv("/FileStore/tables/vendas.csv", header=True, inferSchema=True)
df.show(5)
```

---

### âœ… 3. Tratamento e AnÃ¡lise dos Dados

- RemoÃ§Ã£o de valores nulos
- ConversÃ£o de tipos de dados
- AgregaÃ§Ãµes por regiÃ£o, categoria e data
- OrdenaÃ§Ãµes e filtros por mÃ©tricas

```python
df_clean = df.dropna()
df_clean.groupBy("regiao").agg({"valor": "sum"}).show()


## ğŸ“Š Insights Obtidos

- As regiÃµes **Sudeste** e **Sul** apresentaram os maiores volumes de vendas.
- A maior parte das transaÃ§Ãµes ocorreu nos meses de novembro e dezembro.
- A categoria **EletrÃ´nicos** teve o maior ticket mÃ©dio.

---

## ğŸ’­ Possibilidades Futuras

- Aplicar Machine Learning com **Spark MLlib** para prever vendas
- Criar um dashboard integrado com Power BI
- Automatizar pipeline com Azure Data Factory

---

## ğŸ§  O que eu aprendi

- Criar e configurar ambientes escalÃ¡veis no Azure
- Escrever consultas e transformaÃ§Ãµes com **PySpark**
- Analisar grandes volumes de dados de forma distribuÃ­da
- Organizar um projeto completo com Git e GitHub



**Maria Eduarda Prado** âœ¨  
